{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cebd01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is the first attempt. There are definitely more efficient ways to work with datetimes in\n",
    "# Pandas that would make this go a lot quicker. This is me essentially brute-forcing the analysis\n",
    "# because I'm impatient\n",
    "\n",
    "# ALSO NOTE: Can avoid a lot of the weirdness in the counts by just straight up grabbing the counts\n",
    "# from http://www.nuforc.org/webreports/ndxevent.html ez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c52d13ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4de44c",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c528e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = pd.read_csv('ufo.csv')\n",
    "df2 = pd.read_csv('Keyword_Alien.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6960db15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the movie data //// hopefully won't be necessary once you fix bugs in scrape_imdb.ipynb\n",
    "columns = ['Index','Title','IMDB_Rating','Movie_Description','Release_Date', 'Budget',\\\n",
    "              'Gross_US_Canada', 'Opening_Weekend_US_Canada', 'Gross_Worldwide']\n",
    "df2.columns = columns\n",
    "df2 = df2.drop('Index',1)\n",
    "df2 = df2.drop('Movie_Description',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass_sighting = df1[df1['Posted'] == pd.Timestamp('2020-06-25 00:00:00')]\n",
    "# not exactly mass_sighting but mass posting surge for sure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663fe562",
   "metadata": {},
   "source": [
    "### Get df with count of reports each day and df with list of release dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76efc119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get count of reports for each day in the date/time column (date of sighting)\n",
    "reports['Date / Time'] = pd.to_datetime(reports['Date / Time'])\n",
    "reports = reports[reports['Date / Time'].isna() == False]\n",
    "reports['year'] = reports['Date / Time'].dt.year\n",
    "reports['month'] = reports['Date / Time'].dt.month\n",
    "reports['day'] = reports['Date / Time'].dt.day\n",
    "days = pd.to_datetime(reports[['year','month','day']])\n",
    "days = pd.DataFrame(days)\n",
    "counts = days.pivot_table(columns = 0,aggfunc = 'size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "153833eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get days where an alien movie was released\n",
    "releases = df2['Release_Date']\n",
    "releases = releases.dropna()\n",
    "releases = pd.to_datetime(releases)\n",
    "releases = releases.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d45958e",
   "metadata": {},
   "source": [
    "### Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba4b334f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-14 12:10:33.684147\n",
      "Date: 2008-07-11 00:00:00    Rejected = False\n",
      "Date: 2008-12-12 00:00:00    Rejected = False\n",
      "Date: 2009-03-13 00:00:00    Rejected = False\n",
      "Date: 2009-03-20 00:00:00    Rejected = True\n",
      "Date: 2009-03-27 00:00:00    Rejected = True\n",
      "Date: 2009-04-10 00:00:00    Rejected = True\n",
      "Date: 2009-05-08 00:00:00    Rejected = True\n",
      "Date: 2009-06-24 00:00:00    Rejected = True\n",
      "Date: 2009-08-14 00:00:00    Rejected = False\n",
      "Date: 2009-09-25 00:00:00    Rejected = False\n",
      "Date: 2009-11-06 00:00:00    Rejected = False\n",
      "Date: 2009-12-18 00:00:00    Rejected = False\n",
      "Date: 2010-06-18 00:00:00    Rejected = True\n",
      "Date: 2010-07-09 00:00:00    Rejected = True\n",
      "Date: 2010-11-05 00:00:00    Rejected = False\n",
      "Date: 2010-11-12 00:00:00    Rejected = False\n",
      "Date: 2010-12-03 00:00:00    Rejected = False\n",
      "Date: 2010-12-17 00:00:00    Rejected = False\n",
      "Date: 2011-02-18 00:00:00    Rejected = False\n",
      "Date: 2011-03-18 00:00:00    Rejected = False\n",
      "Date: 2011-05-13 00:00:00    Rejected = True\n",
      "Date: 2011-06-10 00:00:00    Rejected = True\n",
      "Date: 2011-06-17 00:00:00    Rejected = True\n",
      "Date: 2011-06-29 00:00:00    Rejected = True\n",
      "Date: 2011-07-29 00:00:00    Rejected = True\n",
      "Date: 2011-10-14 00:00:00    Rejected = False\n",
      "Date: 2011-12-25 00:00:00    Rejected = True\n",
      "Date: 2012-03-09 00:00:00    Rejected = True\n",
      "Date: 2012-05-04 00:00:00    Rejected = True\n",
      "Date: 2012-05-18 00:00:00    Rejected = True\n",
      "Date: 2012-05-25 00:00:00    Rejected = True\n",
      "Date: 2012-06-08 00:00:00    Rejected = True\n",
      "Date: 2012-07-27 00:00:00    Rejected = True\n",
      "Date: 2013-02-22 00:00:00    Rejected = False\n",
      "Date: 2013-03-29 00:00:00    Rejected = True\n",
      "Date: 2013-04-19 00:00:00    Rejected = True\n",
      "Date: 2013-05-16 00:00:00    Rejected = True\n",
      "Date: 2013-05-31 00:00:00    Rejected = True\n",
      "Date: 2013-06-14 00:00:00    Rejected = True\n",
      "Date: 2013-07-12 00:00:00    Rejected = True\n",
      "Date: 2013-08-23 00:00:00    Rejected = False\n",
      "Date: 2013-09-06 00:00:00    Rejected = False\n",
      "Date: 2013-11-01 00:00:00    Rejected = False\n",
      "Date: 2014-02-07 00:00:00    Rejected = False\n",
      "Date: 2014-03-14 00:00:00    Rejected = False\n",
      "Date: 2014-06-06 00:00:00    Rejected = True\n",
      "Date: 2014-06-27 00:00:00    Rejected = True\n",
      "Date: 2014-07-10 00:00:00    Rejected = False\n",
      "Date: 2014-08-01 00:00:00    Rejected = False\n",
      "Date: 2015-02-06 00:00:00    Rejected = False\n",
      "Date: 2015-03-27 00:00:00    Rejected = False\n",
      "Date: 2015-07-24 00:00:00    Rejected = True\n",
      "Date: 2015-12-18 00:00:00    Rejected = False\n",
      "Date: 2016-01-22 00:00:00    Rejected = False\n",
      "Date: 2016-03-11 00:00:00    Rejected = False\n",
      "Date: 2016-03-25 00:00:00    Rejected = False\n",
      "Date: 2016-06-03 00:00:00    Rejected = True\n",
      "Date: 2016-06-24 00:00:00    Rejected = True\n",
      "Date: 2016-07-22 00:00:00    Rejected = True\n",
      "Date: 2016-11-11 00:00:00    Rejected = False\n",
      "Date: 2016-12-16 00:00:00    Rejected = False\n",
      "Date: 2017-02-03 00:00:00    Rejected = False\n",
      "Date: 2017-03-24 00:00:00    Rejected = False\n",
      "Date: 2017-03-24 00:00:00    Rejected = False\n",
      "Date: 2017-05-05 00:00:00    Rejected = True\n",
      "Date: 2017-05-12 00:00:00    Rejected = True\n",
      "Date: 2017-05-19 00:00:00    Rejected = True\n",
      "Date: 2017-06-21 00:00:00    Rejected = True\n",
      "Date: 2017-07-21 00:00:00    Rejected = False\n",
      "Date: 2017-07-21 00:00:00    Rejected = False\n",
      "Date: 2017-09-08 00:00:00    Rejected = False\n",
      "Date: 2017-11-03 00:00:00    Rejected = False\n",
      "Date: 2017-11-17 00:00:00    Rejected = False\n",
      "Date: 2017-12-15 00:00:00    Rejected = False\n",
      "Date: 2017-12-15 00:00:00    Rejected = False\n",
      "Date: 2018-02-23 00:00:00    Rejected = False\n",
      "Date: 2018-03-23 00:00:00    Rejected = False\n",
      "Date: 2018-04-06 00:00:00    Rejected = False\n",
      "Date: 2018-04-27 00:00:00    Rejected = True\n",
      "Date: 2018-05-25 00:00:00    Rejected = True\n",
      "Date: 2018-06-13 00:00:00    Rejected = True\n",
      "Date: 2018-09-14 00:00:00    Rejected = False\n",
      "Date: 2018-10-05 00:00:00    Rejected = False\n",
      "Date: 2018-12-14 00:00:00    Rejected = False\n",
      "Date: 2018-12-21 00:00:00    Rejected = False\n",
      "Date: 2019-02-08 00:00:00    Rejected = True\n",
      "Date: 2019-03-08 00:00:00    Rejected = True\n",
      "Date: 2019-03-15 00:00:00    Rejected = True\n",
      "Date: 2019-04-26 00:00:00    Rejected = True\n",
      "Date: 2019-05-24 00:00:00    Rejected = True\n",
      "Date: 2019-05-24 00:00:00    Rejected = True\n",
      "Date: 2019-05-31 00:00:00    Rejected = True\n",
      "Date: 2019-06-07 00:00:00    Rejected = True\n",
      "Date: 2019-06-14 00:00:00    Rejected = True\n",
      "Date: 2019-06-14 00:00:00    Rejected = True\n",
      "Date: 2019-06-21 00:00:00    Rejected = True\n",
      "Date: 2019-07-02 00:00:00    Rejected = True\n",
      "Date: 2019-12-20 00:00:00    Rejected = False\n",
      "Date: 2020-02-09 00:00:00    Rejected = True\n",
      "Date: 2020-02-14 00:00:00    Rejected = True\n",
      "Date: 2020-05-29 00:00:00    Rejected = False\n",
      "Date: 2020-09-10 00:00:00    Rejected = False\n",
      "Date: 2020-11-20 00:00:00    Rejected = False\n",
      "Date: 2020-12-25 00:00:00    Rejected = False\n",
      "Date: 2021-03-05 00:00:00    Rejected = True\n",
      "Date: 2021-03-12 00:00:00    Rejected = True\n",
      "Date: 2021-03-18 00:00:00    Rejected = True\n",
      "Date: 2021-05-28 00:00:00    Rejected = False\n",
      "Date: 2021-06-01 00:00:00    Rejected = False\n",
      "Date: 2021-07-02 00:00:00    Rejected = False\n",
      "Date: 2021-07-15 00:00:00    Rejected = False\n",
      "Date: 2021-08-05 00:00:00    Rejected = False\n",
      "Portion of samples which saw an increase in average counts following movie release: 0.49107142857142855\n"
     ]
    }
   ],
   "source": [
    "# for each day a movie was released, find prior/post counts\n",
    "greater = 0\n",
    "lesser = 0\n",
    "# make a cutoff date about 3 months prior. Sightings are rarely posted to the site within 3 months.\n",
    "cutoff_date = pd.Timestamp.today() - pd.Timedelta(days=120)\n",
    "print(cutoff_date)\n",
    "for date in releases:\n",
    "    # Find movie corresponding to date ///// Or revamp how we interact w releases file to bring\n",
    "    # movie title along with date of release ///// Would need to modify lots of stuff in this block\n",
    "    \n",
    "    # check that the movie wasn't released too recently\n",
    "    if date > cutoff_date:\n",
    "        continue\n",
    "        \n",
    "    # Make range of dates n days in the past\n",
    "    prior_start = date - pd.Timedelta('90 days')\n",
    "    count = 0\n",
    "    prior_period = []\n",
    "    while count != 90:\n",
    "        prior_period.append(prior_start + pd.Timedelta(days=count))\n",
    "        count += 1\n",
    "        \n",
    "    # grab counts of all days that fall in prior_period\n",
    "    total_prior = 0\n",
    "    for day in prior_period:\n",
    "        if day in counts:\n",
    "            total_prior += counts.loc[day]\n",
    "            \n",
    "    # Make range of dates  n days in the future\n",
    "    count = 1\n",
    "    post_period = []\n",
    "    while count != 90:\n",
    "        post_period.append(date + pd.Timedelta(days=count))\n",
    "        count += 1\n",
    "    \n",
    "    # grab counts of all days that fall in post_period\n",
    "    total_post = 0\n",
    "    for day in post_period:\n",
    "        if day in counts:\n",
    "            total_post += counts.loc[day]\n",
    "    \n",
    "    # skip if no reports data surrounding the movie\n",
    "    if total_prior == 0 or total_post == 0:\n",
    "        continue\n",
    "    \n",
    "    # find average of each group\n",
    "    average_prior = total_prior/len(prior_period)\n",
    "    average_post = total_post/len(post_period)\n",
    "    \n",
    "    # find sample standard deviations\n",
    "    squared_diff = 0\n",
    "    prior_samples = 0\n",
    "    for day in prior_period:\n",
    "        if day in counts:\n",
    "            squared_diff += (counts.loc[day]-average_prior)**2\n",
    "            prior_samples += 1\n",
    "    std_prior = (squared_diff/(prior_samples-1))**(0.5)\n",
    "    \n",
    "    squared_diff = 0\n",
    "    post_samples = 0\n",
    "    for day in post_period:\n",
    "        if day in counts:\n",
    "            squared_diff += (counts.loc[day]-average_post)**2\n",
    "            post_samples += 1\n",
    "    std_post = (squared_diff/(post_samples-1))**(0.5)\n",
    "            \n",
    "    standard_error = (std_prior**2/(prior_samples-1) + std_post**2/(post_samples-1))**(0.5) \n",
    "    \n",
    "    \n",
    "    #print(f'Date:{date}\\n Avg_Prior: {\"{:.2f}\".format(average_prior)}   \\\n",
    "    #Avg_Post: {\"{:.2f}\".format(average_post)} \\nstd_prior: {\"{:.2f}\".format(std_prior)}   \\\n",
    "    #std_post {\"{:.2f}\".format(std_post)} \\n Standard Error: {\"{:.2f}\".format(pooled_sd)}')   \n",
    "      \n",
    "    # run two sample inference:\n",
    "        # H0: avg_post == avg_prior\n",
    "        # versus\n",
    "        # H1: avg_post > avg_prior\n",
    "    # Reject H_0 if t >= t_(alpha),n+m-2\n",
    "    test_statistic = (average_post-average_prior)/standard_error\n",
    "    alpha = 0.10\n",
    "    critical_value = t.ppf(1-alpha,df=post_samples+prior_samples-2)\n",
    "    rejected = test_statistic >= critical_value\n",
    "    \n",
    "    print(f'Date: {date}    Rejected = {rejected}')\n",
    "    \n",
    "    if rejected:\n",
    "        greater += 1\n",
    "    else:\n",
    "        lesser += 1\n",
    "        \n",
    "# calculate p = greater_counter/(greater_counter + lesser_counter)\n",
    "# one-tailed binomial test H0: p = 0.5 versus H1: p > 0.5\n",
    "print(f'Portion of samples which saw an increase in average counts \\\n",
    "following movie release: {greater/(greater+lesser)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ec9ef",
   "metadata": {},
   "source": [
    "## Initial thoughts after analysis on 1/12/2022\n",
    "\n",
    "### Sampling Technique\n",
    "\n",
    "1. For some reason we aren't getting any data for movies prior to 2009. This might be due to our sparser UFO reporting data as we go back in time (so it's harder to capture reports around the movie releases).\n",
    "2. Might want/need a more intelligent way of picking time bounds.\n",
    "3. **Maybe shift gears from analysis of all movies to analysis of specific movies?** I do think that once we can actually get data for older movies these results might change. The concept of alien movies affecting UFO reportings seems like an older one... people our generation probably wouldn't make the connection. However someone seeing War of the Worlds for the first time certainly might.\n",
    "\n",
    "### Results\n",
    "It looks like with the way I'm currently gathering data we do not have evidence to support upost>uprior\n",
    "\n",
    "I want to adjust my sampling technique and see if this changes (While also making sure I'm not pushing the results one way or the other).\n",
    "\n",
    "Possible new strategies (for analysis of all movies):\n",
    "\n",
    "1. It might be interesting to weight each sample by box office amounts? That way we can account for the \n",
    "fact that some movies are far more popular than others. For now, let's try to figure out which movies did see an increase in u_counts.\n",
    "\n",
    "2. Might want to revamp the selection process for releases. Maybe only look at the most popular alien movie each year, and then look at before/after counts for that year?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
